{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5242901-2247-4102-a1ab-8c259b5b525b",
   "metadata": {},
   "source": [
    "# Alignment in human-voice assistant interaction\n",
    "\n",
    "Find the exposé for my PhD project below.\n",
    "\n",
    "## Exposé\n",
    "\n",
    "Alignment describes the psycholinguistic phenomenon that interlocutors tend to converge on multiple linguistic levels in the course of an interaction, e.g., on the lexical level: If speaker A introduces expression X to refer to some entity, their interlocutor, speaker B, is more likely to reuse the same expression X to refer to the same entity than to use lexical equivalents (Pickering & Garrod, 2004; Szmrecanyi, 2005; Koulouri et al., 2016). This tendency has been established both for human-human interaction (Branigan et al., 2000) and human-machine interaction, for the latter among others for lexis (Branigan & Pearson, 2016; Huiyang & Min, 2022), syntax (Heyselaar et al., 2017) and prosody (Raveh et al, 2019) as well as for different settings such as interactions with chatbots (written; Lotze, 2016), robots (oral, gestural; Fischer, 2016) and voice assistants (VAs; oral; Linnemann & Jucks, 2018). The phenomenon has been accounted for by different, non-exclusive explanations including a pre-conscious priming mechanism (Pickering & Garrod, 2004), the mindless application of social rules onto artificial beings (Reeves & Nass, 1996), and conscious, strategic simplification (Zoeppritz, 1988). \n",
    "\n",
    "Most research into alignment in human-machine interaction (HMI) has relied on experiments, typically employing a picture-naming-matching task (PNM) whereby the machine (or the wizard in Wizard-of-Oz settings) uses a certain structure (e.g., active rather than passive, for syntactic alignment) to describe a given picture. In their subsequent turn participants are then more likely to use the same structure to describe a different picture stimulus, thus syntactically aligning to their interlocutor (Pearson et al., 2006, Heyselaar et al., 2017). While such a task is highly controllable, the fact that a PNM scenario has no clear link to real-life HMI as well as its pre-defined two-turn nature may lower the ecological validity of such findings. Pursuing a corpus-based approach, then, one cannot directly account for alignment processes in the brain, but only document the persistence of linguistic structures, which may be hypothesized to be the result of a cognitive alignment mechanism (Lotze, 2016). On the other hand, corpus-based research offers the advantage that data from (more or less) authentic interactions between humans and actual machines can be investigated. Even so, there are only few corpus-based studies into persistence in HMI. One notable exception is Lotze (2016) who studied the issue in chatbot interactions in German and found widespread evidence for both lexical and syntactic persistence. Yet missing is corpus-based research into persistence in interactions between humans and VAs which in the form of Alexa, Siri and the like are entering the lives of more and more people (Byrne et al., 2019; Yuan et al., 2020). This project aims to fill this research gap by investigating persistence in human-VA interaction, pursuing (primarily) a corpus-based approach.\n",
    "\n",
    "For that purpose, (at least) two German-language corpora from interactions between humans and Alexa will be analyzed regarding lexical and syntactic persistence, applying the classification scheme PerLexSy developed by Lotze (2016; based on Branigan et al., 2000; Pickering & Garrod, 2004; Gries, 2005; Szmrecanyi, 2005). Experimental results (see above) and corpus-based findings from similar interactions (Lotze, 2016) suggest that persistent structures should also be present in human-VA interaction data. The extent of which may be modulated by context-specific variables: Compared to chatbots, human-VA interaction is not only conceptually oral, but also medially, moving it closer to natural human-human interaction. At the same time, the technology behind VAs is newer and more complex (involving ASR and TTS) compared to chatbots as well as smoothly running machines/wizards in tightly controlled experiments. Interactions with VAs are thus more error-prone, rendering them less natural. These contradictory variables make investigating persistence (and, by extension, alignment) in human-VA interaction interesting. First impressions from the data suggest that lexical (non-)alignment is conditioned by whether humans have evidence that a given (different) expression can be parsed by the VA’s NLU, or not.\n",
    "\n",
    "## Literature\n",
    "\n",
    "- Branigan, H., & Pearson, J. (2006). Alignment in human-computer interaction. In K. Fischer (Ed.), Proceedings of the Workshop on How people talk to computers, robots, and other artificial communication partners (pp. 140–156). Hanse-Wissenschaftskolleg Institute for Advanced Study.\n",
    "- Branigan, H. P., Pickering, M. J., & Cleland, A. A. (2000). Syntactic co-ordination in dialogue. Cognition, 75(2), B13–B25. https://doi.org/10.1016/S0010-0277(99)00081-5\n",
    "- Byrne, B., Krishnamoorthi, K., Sankar, C., Neelakantan, A., Duckworth, D., Yavuz, S., Goodrich, B., Dubey, A., Cedilnik, A., & Kim, K. Y. (2019). Taskmaster-1: Toward a realistic and diverse dialog dataset. EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference, 4516–4525. https://doi.org/10.18653/v1/d19-1459\n",
    "- Fischer, K. (2016). Designing Speech for a Recipient: The roles of partner modeling, alignment and feedback in so-called ‘simplified registers’ (Vol. 270). John Benjamins. https://doi.org/10.1075/pbns.270\n",
    "- Gries, S. Th. (2005). Syntactic Priming: A Corpus-based Approach. Journal of Psycholinguistic Research, 34(4), 365–399. https://doi.org/10.1007/s10936-005-6139-3  \n",
    "- Heyselaar, E. (2017). Influences on the magnitude of syntactic priming. Radboud University Nijmegen.\n",
    "- Huiyang, S., & Min, W. (2022). Improving Interaction Experience through Lexical Convergence: The Prosocial Effect of Lexical Alignment in Human-Human and Human-Computer Interactions. International Journal of Human-Computer Interaction, 38(1), 28–41. https://doi.org/10.1080/10447318.2021.1921367\n",
    "- Koulouri, T., Lauria, S., & Macredie, R. D. (2016). Do (and Say) as I Say: Linguistic adaptation in human–computer dialogs. Human-Computer Interaction, 31(1), 59–95. https://doi.org/10.1080/07370024.2014.934180\n",
    "- Linnemann, G. A., & Jucks, R. (2018). ’Can i Trust the Spoken Dialogue System because It Uses the Same Words as i Do?’—Influence of Lexically Aligned Spoken Dialogue Systems on Trustworthiness and User Satisfaction. Interacting with Computers, 30(3), 173–186. https://doi.org/10.1093/iwc/iwy005\n",
    "- Lotze, N. (2016). Chatbots: Eine linguistische Analyse (Vol. 9). Peter Lang. https://doi.org/10.3726/b10402\n",
    "- Pearson, J., Hu, J., Branigan, H. P., Pickering, M. J., & Nass, C. I. (2006). Adaptive language behavior in HCI. July 2017, 1177–1180. https://doi.org/10.1145/1124772.1124948\n",
    "- Pickering, M. J., & Garrod, S. (2004). Toward a mechanistic psychology of dialogue. Behavioral and Brain Sciences, 27(2), 169–190. https://doi.org/10.1017/S0140525X04000056\n",
    "- Raveh, E., Siegert, I., Steiner, I., Gessinger, I., & Möbius, B. (2019). Three’s a Crowd? Effects of a Second Human on Vocal Accommodation with a Voice Assistant. Interspeech 2019, 4005–4009. https://doi.org/10.21437/Interspeech.2019-1825\n",
    "- Reeves, B., & Nass, C. (1996). The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places. The Center for the Study of Language and Information Publications.\n",
    "- Siegert, I. (2020). “Alexa in the wild”—Collecting unconstrained conversations with a modern voice assistant in a public environment. Proceedings of the 12th International Conference on Language Resources and Evaluation, Marseille, 615–619. https://www.aclweb.org/anthology/2020.lrec-1.77/\n",
    "- Szmrecsanyi, B. (2005). Language users as creatures of habit: A corpus-based analysis of persistence in spoken English. Corpus Linguistics and Linguistic Theory, 1(1), 113–149. https://doi.org/10.1515/cllt.2005.1.1.113\n",
    "- Yuan, S., Brüggemeier, B., Hillmann, S., & Michael, T. (2020). User Preference and Categories for Error Responses in Conversational User Interfaces. ACM International Conference Proceeding Series. https://doi.org/10.1145/3405755.3406126\n",
    "- Zoeppritz, M. (1988). ’Kommunikation’ mit der Maschine. In R. Weingarten & R. Fiehler (Eds.), Technisierte Kommunikation. Psycholinguistische Studien. (pp. 109–121). VS Verlag für Sozialwissenschaften. https://doi.org/10.1007/978-3-322-86319-5_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f7ebc-94d0-4148-847c-37a5b03a40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}